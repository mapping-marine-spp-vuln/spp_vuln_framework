---
title: "Expand taxonomic groups from expert data"
author: "*Compiled on `r date()` by `r Sys.info()['user']`*"
output: 
  html_document:
    code_folding: hide
    toc: true
    toc_depth: 3
    toc_float: yes
    number_sections: true
    theme: cerulean
    highlight: haddock
    includes: 
      in_header: '~/github/src/templates/ohara_hdr.html'
  pdf_document:
    toc: true
---

``` {r setup, echo = TRUE, message = FALSE, warning = FALSE}

knitr::opts_chunk$set(fig.width = 6, fig.height = 4, fig.path = 'figs/',
                      echo = TRUE, message = FALSE, warning = FALSE)

source('https://raw.githubusercontent.com/oharac/src/master/R/common.R')
library(taxize)   ### remotes::install_github("ropensci/taxize")
# library(taxizedb) ### remotes::install_github("ropensci/taxizedb")
# taxizedb::db_download_ncbi()
# taxizedb::src_ncbi()
# taxizedb::db_download_gbif()

```

# Summary

From the taxonomic names given by the taxon experts, expand both upward and downward to create an all-inclusive marine species list.

Use the `taxize` package:

* `taxize::classification()` to get the entire taxonomic hierarchy of a given taxon ID.
* `taxize::children()` to get immediate taxonomic children for a given taxon
* `taxize::downstream()` to get names down to a specified rank, e.g., getting all species in a family.

```{r}
### create a function to break up large species lists into chunks,
### saving to tmp, in case of breaks in internet connectivity
classify_chunks <- function(spp_gps, chunk_size = 20, db = 'worms', overwrite = FALSE) {
  ### spp_gps is a character vector
  n_chunks <- ceiling(length(spp_gps) / chunk_size)
  tmpstem <- here('tmp/taxize_classification_all_%s.csv')
  if(overwrite == TRUE) {
    unlink(here('tmp/taxize_classification_all_*.csv'))
  }
  for(i in 1:n_chunks) { ### i <- 1
    message('Processing chunk ', i, ' of ', n_chunks)
    indices <- c(1 + chunk_size * (i - 1), min(length(spp_gps), chunk_size * i))
    chunk_file <- sprintf(tmpstem, paste0(indices, collapse = '_'))
    if(!file.exists(chunk_file)) {
      tmp_gps <- spp_gps[indices[1]:indices[2]]
      
      chunk_results <- taxize::classification(tmp_gps, db = db, rows = 1)
      
      chunk_check <- sapply(chunk_results, is.data.frame)
      chunk_ok <- chunk_results[chunk_check]
      
      chunk_df <- bind_rows(chunk_ok, .id = 'spp_gp') 

      error_results <- chunk_results[!chunk_check]
      if(length(error_results) > 0) {
        message('chunk ', i, ' returned ', length(error_results),
                ' errors out of ', length(tmp_gps))
        chunk_errors <- data.frame(spp_gp = names(error_results),
                                   error = TRUE)
        chunk_df <- chunk_df %>%
          bind_rows(chunk_errors)
      }
    
      write_csv(chunk_df, chunk_file)
    }
  }
  
  tmp_files <- list.files(here('tmp'), pattern = sprintf('taxize_classification_all'),
                          full.names = TRUE)
  
  results_all <- lapply(tmp_files, 
                        FUN = function(f) {
                          read_csv(f, col_types = cols(.default = 'c'))
                        }) %>%
    bind_rows() %>%
    mutate(error = ifelse(!'error' %in% names(.), NA, error),
           error = ifelse(is.na(error), FALSE, error),
           error = as.logical(error))
  return(results_all)
}

```

# Methods

## Match up taxonomic info from experts to names in taxonomic databases.

Using `taxize::classification()`, check each taxonomic name against databases of taxonomic info to get the full upstream classification.  We do this twice: once for NCBI to get upstream ID numbers for the downstreaming process, and once iterating to catch all species in the expert trait data.

Order of search for the iterative process:
* WoRMS (left 38 unmatched out of 841)
* NCBI (left 15 still unmatched out of 841)
* GBIF (left 4 down)
* EOL (found the rest - NOTE: this was not a preferred db because some names had extra info, e.g. citation)

```{r NCBI only, eval = FALSE}
spp_traits <- read_csv('_data/spp_traits_valid.csv')

### This queries for all species
# spp_gps <- spp_traits %>%
#   select(taxon, spp_gp) %>%
#   mutate(name = tolower(spp_gp)) %>%
#   .$spp_gp %>% unique()
# 
# y <- classify_chunks(spp_gps, db = 'worms') %>%
#   mutate(db = 'ncbi')
# 
# write_csv(y, here('int/taxize_results_ncbi.csv'))
```

```{r WoRMS starting point, eval = FALSE}
spp_traits <- read_csv('_data/spp_traits_valid.csv')

### This queries for all species
# spp_gps <- spp_traits %>%
#   select(taxon, spp_gp) %>%
#   mutate(name = tolower(spp_gp)) %>%
#   .$spp_gp %>% unique()
# 
# y <- classify_chunks(spp_gps, db = 'worms') %>%
#   mutate(db = 'gbif')
# 
# write_csv(y, here('int/taxize_results_all.csv'))
```

``` {r iteration, eval = FALSE}
### this can be iterated to fill gaps.  
### Note: For GBIF seems to fail often when searching for genus/family name.
### Try downstreaming to species level then searching again.

y <- read_csv(here('int/taxize_results_all.csv')) %>%
  filter(spp_gp %in% spp_traits$spp_gp) %>%
  left_join(spp_traits %>% select(spp_gp, taxon) %>% distinct())

### any new groups?
yy <- spp_traits %>%
  filter(!spp_gp %in% y$spp_gp) %>%
  .$spp_gp %>% unique()
spp_gps_error <- y %>%
  filter(error | is.na(id)) %>%
  .$spp_gp %>% unique()

db = 'ncbi'
z <- classify_chunks(c(yy, spp_gps_error), db = db, overwrite = TRUE) %>%
  mutate(db = db)

z %>% filter(error) %>% .$spp_gp %>% n_distinct()
# z_eol
### 14 still unmatched with WORMS; 6 still unmatched with GBIF; EOL finds the
### rest though still need to break out cephs

zz <- y %>%
  filter(!error) %>%
  bind_rows(z %>% mutate(id = as.numeric(id))) %>%
  select(-taxon)

write_csv(zz, here('int/taxize_results_all.csv'))

```

## Get structured downstream species based on higher ranks using NCBI

Here we will use NCBI data to get downstream ranks for all classes represented in the species traits data.  This will give us the structure of the trees moving down toward species, so each species will also have information on genus, family, order, etc.  NCBI data allows us to use `taxizedb` and a local database for much faster (relatively) processing.

Using NCBI at the class level will inevitably give us a lot of freshwater and terrestrial species, so we will also do a simpler downstream search using WoRMS to get all families, genera, and species for the classes represented in the traits data, but without the structure - this will allow us to do some filtering of the NCBI data, and also fill in some gaps.  The simpler search is necessary because WoRMS does not work with `taxizedb` so the structured downstream search is unworkable.

### Class match

Filter to just the "main" ranks, and then use that to get downstream species.  The process here is not using the `downstream` function, as that loses intermediate structure (though it can return intermediate levels, those are not structured).  Instead, for each iteration, use `children` to get immediate children, then from those children, use `children` again and so on, until reaching the end of the chain or the species level, whichever comes first.

See https://github.com/ropensci/taxize/issues/830#issuecomment-646236702 for notes on taxizedb, downloading NCBI database and working from that locally.  (Now using WoRMS as the primary source, to ensure marine species only)

```{r get_all_children functions}
### create a function to get and interpret downstream matches for a given taxon,
### saving to intermediate, in case of breaks in internet connectivity.  
### taxa is a dataframe containing the id and name for a given rank;
### start_rank is the level of that first dataframe.

gather_levels <- function(df, start_rank, start_taxa, upstream) {
  ranks <- c('kingdom', 'phylum', 'class', 'subclass', 
             'superorder', 'order', 'suborder', 
             'family', 'subfamily', 'genus', 'species')
  if(nrow(df) > 1) stop('gimme just one row to fix, plz')
  df1 <- df %>%
    mutate(rank0 = start_rank,
           id0   = start_taxa$id) %>%
    gather(ranklevel, rank, starts_with('rank')) %>%
    gather(namelevel, name, starts_with('name')) %>%
    gather(idlevel,   id,   starts_with('id')) %>%
    ### make sure that name, rank, and id levels match
    filter(str_extract(namelevel, '[0-9]+') == str_extract(ranklevel, '[0-9]+')) %>%
    filter(str_extract(namelevel, '[0-9]+') == str_extract(idlevel, '[0-9]+')) %>%
    bind_rows(upstream) %>%
    select(rank, name, id) %>%
    distinct() %>%
    mutate(rank = factor(rank, levels = ranks)) %>%
    filter(!is.na(name) & !is.na(rank)) %>%
    arrange(rank) %>%
    mutate(species = last(name))
  
  return(df1)
}

get_all_children <- function(start_taxa, start_rank = 'class', 
                             db, overwrite = FALSE) {
  # start_taxa <- class_db[1, ]
  # start_rank <- 'class'
  start_taxa <- start_taxa %>%
    mutate(name = tolower(name))
  tmpstem <- file.path('~/git-annex/spp_vuln/taxa_class', 
                       'taxize_downstream_%s_%s.csv')
  outfile <- sprintf(tmpstem, start_taxa$name, db)
  if(overwrite == TRUE) {
    unlink(outfile)
  }
  
  if(!file.exists(outfile)) {
    message('processing ', outfile)
    result_list <- vector('list', length = 50)
    
    i <- 0
    taxa <- start_taxa
    while(nrow(taxa) > 0) {
      i <- i + 1
      message('iterating level ', i)

      ds_result <- taxizedb::children(x = taxa$id, db = database)
      
      ds_df <- ds_result %>%
        # rlang::as_list() %>% ### coerces, rather than converts like as.list()
        setNames(taxa$name) %>%
        bind_rows(.id = 'parent') %>%
        setNames(str_replace_all(names(.), 'childtaxa_', '')) %>%
        mutate(rank = tolower(rank))

      result_list[[i]] <- ds_df
      taxa <- ds_df %>%
        filter(rank != 'species') %>% ### drops errors, convenient
        select(-parent)
      
    }
    result_list <- result_list[1:i]
    
    message('binding list')
    
    full_df <- bind_rows(result_list) %>%
      mutate(name = tolower(name), parent = tolower(parent)) %>%
      rename(name1 = name, rank1 = rank, id1 = id, name0 = parent)
    if('error' %in% names(full_df)) {
      full_df <- full_df %>% filter(!error | is.na(error)) %>%
        select(-error)
    }

    tmp_df <- full_df
    
    for(j in 2:i) {
      ### j <-2
      oldname <- paste0('name', j-1)
      newname <- paste0('name', j)
      newrank <- paste0('rank', j)
      newid   <- paste0('id', j)
      ### fix names without variables; rename after
      join_df <- full_df %>%
        rename(newname = name1,
               newid   = id1,
               newrank = rank1,
               parent = name0)
               
      tmp_df <- tmp_df %>%
        rename(parent := oldname) %>%
        left_join(join_df, tmp_df, by = c('parent')) %>%
        rename(!!oldname := parent,
               !!newname := newname,
               !!newid   := newid,
               !!newrank := newrank)
    }
    
    tmp_df <- tmp_df %>%
      distinct()
    nrows <- nrow(tmp_df)
    message('cleaning data frame: ', nrows, ' rows')
    upstream <- classification(start_taxa$id, db = db)[[1]] %>%
      filter(rank %in% ranks) %>%
      mutate(name = tolower(name))
      
    clean_df <- parallel::mclapply(1:nrow(tmp_df), 
                                   mc.cores = ifelse(Sys.info()['sysname'] == 'Linux', 32, 1),
        FUN = function(i) {
          if(i %% 1000 == 0) message('cleaning row: ', i, ' of ', nrows)
          df <- tmp_df[i, ]
          gather_levels(df, start_rank, start_taxa, upstream)
        }) %>%
      bind_rows() %>%
      distinct()
    
    write_csv(clean_df, outfile)
  }
  
  clean_df <- read_csv(outfile)

  return(clean_df)
}
```

```{r run the class level get_all_children function}

taxize_results_ncbi <- read_csv(here('int/taxize_results_ncbi.csv'))

### filter down to NCBI
class_db <- taxize_results_ncbi %>%
  mutate(name = tolower(name), rank = tolower(rank)) %>%
  filter(rank == 'class') %>%
  group_by(id, name) %>%
  summarize(n_gps = n_distinct(spp_gp)) %>%
  ungroup() %>%
  arrange(n_gps)

for(i in 1:nrow(class_db)) {
  ### i <- 17
  taxa <- class_db[i, ]
  cat('Processing ', taxa$name, '...\n')
  x <- get_all_children(start_taxa = taxa,
                        start_rank = 'class',
                        db = 'ncbi', overwrite = FALSE)
}
```

Noticing some odd "class" level names that are actually genus names - e.g. abalistes.

Fix those:
```{r, eval = FALSE}
files <- list.files('~/git-annex/spp_vuln/taxa_class',
                    pattern = 'taxize_downstream_.+_ncbi',
                    full.names = TRUE)
for (f in files) {
  ### f <- files[1]
  taxon <- str_replace_all(basename(f), '.+stream_|_ncbi.+', '')
  x <- data.table::fread(f)
  y <- x %>%
    filter(rank != 'class' | name == taxon)
  write_csv(y, f)
}
```

## Get structured downstream from WoRMS

Here let's start at the kingdom level, and find all classes in WoRMS to identify any classes missing from our NCBI structured tree.  

```{r run the class level downstream function}

c_from_k_file <- here('int/class_from_kingdom_worms.csv')

if(!file.exists(c_from_k_file)) {
  taxize_results_all <- read_csv(here('int/taxize_results_all.csv'))
  
  kingdom_all_df <- taxize_results_all %>%
    mutate(name = tolower(name), rank = tolower(rank)) %>%
    filter(rank == 'kingdom') %>%
    # filter(db == 'worms') %>%
    group_by(name) %>%
    summarize(n_gps = n_distinct(spp_gp)) %>%
    ungroup() %>%
    arrange(n_gps)
  
  kingdoms <- kingdom_all_df$name
  tmp_list <- vector('list', length = length(kingdoms)) %>%
    setNames(kingdoms)
  for(k in kingdoms) {
    ### k <- kingdoms[1]
    message('Processing ', k)
    c_from_k <- taxize::downstream(sci_id = k, db = 'worms', downto = 'class')
    tmp_list[[k]] <- c_from_k[[1]]
  }
  
  tmp_list <- tmp_list[!is.na(tmp_list)]
  c_from_k_df <- tmp_list %>%
    bind_rows(.id = 'kingdom') %>%
    mutate(name = tolower(name))
  
  write_csv(c_from_k_df, c_from_k_file)
}
```

From the classes in WoRMS under each kingdom, get downstream information for each class.  Here we use the `downstream` function, with `intermediate = FALSE`.  We will do this iteratively for class --> order, order --> family, family --> genus, and genus --> species.  This way we can reassemble the structure.

```{r}
  
get_downstream <- function(gp_df, db = 'worms', downto, downfrom, namestem, id_type = 'id') {
  ### NOTE: in WoRMS some names have multiple IDs.  Use name to 
  gp_df <- gp_df %>%
    mutate(name = str_trim(tolower(name)))
  names <- gp_df$name %>% unique()
  
  for(pname in names) {
    ### pname <- names[1]
    tmp_file <- sprintf(here('tmp/%s_%s_%s.csv'), namestem, db, pname)
    if(!file.exists(tmp_file)) {
      ids   <- gp_df$id[gp_df$name == pname]
      
      tx_out_df <- data.frame() ### blank one
      for(id in ids) {
        message('Processing ', pname, ' - ', id)
        id_tx_out <- taxize::downstream(sci_id = ifelse(id_type == 'name', pname, id), db = db, 
                                     downto = downto)
        id_tx_out_df <- id_tx_out[[1]] 
        
        if(nrow(id_tx_out_df) == 0) {
          id_tx_out_df <- data.frame(name = NA, rank = NA) 
        }
        tx_out_df <- bind_rows(tx_out_df, id_tx_out_df)
      }
      
      tx_out_df <- tx_out_df %>%
        mutate(parent = pname, parent_level = downfrom)
      write_csv(tx_out_df, tmp_file)
    }
  }
  tmp_files <- list.files(here('tmp'), pattern = sprintf('%s_%s_.+.csv', namestem, db),
                          full.names = TRUE)
  
  tx_out_all <- parallel::mclapply(tmp_files, read_csv) %>%
    bind_rows() %>%
    mutate_if(is.character, tolower)
  
  return(tx_out_all)
}
```

```{r order from class}
o_from_c_file <- here('int/order_from_class_worms.csv')

if(!file.exists(o_from_c_file)) {
  gp_df <- read_csv(c_from_k_file)
  
  o_from_c_df <- get_downstream(gp_df, downto = 'order', downfrom = 'class', namestem = 'o_from_c')

  write_csv(o_from_c_df, o_from_c_file)
}

```

```{r family from order}
f_from_o_file <- here('int/family_from_order_worms.csv')

if(!file.exists(f_from_o_file)) {
  gp_df <- read_csv(o_from_c_file) %>%
    filter(!is.na(id))
  
  f_from_o_df <- get_downstream(gp_df, downto = 'family', downfrom = 'order', 
                                 namestem = 'f_from_o')
  
  write_csv(f_from_o_df, f_from_o_file)
}

```

```{r species from family}
### skip genus since it is included in species - though risks dropping genera
### with no species in them? is that a thing? let's not worry about it now.

s_from_f_file <- here('int/species_from_family_worms.csv')

if(!file.exists(s_from_f_file)) {
  gp_df <- read_csv(f_from_o_file) %>%
    filter(!is.na(id))
  
  s_from_f_df <- get_downstream(gp_df, downto = 'species', downfrom = 'family', 
                                 namestem = 's_from_f')
  
  write_csv(s_from_f_df, s_from_f_file)
}

```


### compare numbers of species

```{r}
nspp_family <- family_level_df %>%
  filter(rank == 'class') %>%
  group_by(name) %>%
  summarize(n_spp_fam = n_distinct(species)) %>%
  bind_rows(family_level_df %>%
              filter(rank == 'class') %>%
              summarize(name = 'total', n_spp_fam = n_distinct(species)))

### gather class-level into one file
tmpfiles <- list.files('~/git-annex/spp_vuln/taxa_class', 
                       pattern = 'taxize_downstream_.+ncbi',
                       full.names = TRUE)
class_level_df <- lapply(tmpfiles, read_csv) %>%
  bind_rows()
nspp_class <- class_level_df %>%
  filter(rank == 'class') %>%
  group_by(name) %>%
  summarize(n_spp_class = n_distinct(species)) %>%
  bind_rows(class_level_df %>%
              filter(rank == 'class') %>%
              summarize(name = 'total', n_spp_class = n_distinct(species)))

nspp <- full_join(nspp_family, nspp_class, by = 'name')
knitr::kable(nspp)
```

