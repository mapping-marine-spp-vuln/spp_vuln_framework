---
title: "Expand taxonomic groups from expert data"
author: "*Compiled on `r date()` by `r Sys.info()['user']`*"
output: 
  html_document:
    code_folding: hide
    toc: true
    toc_depth: 3
    toc_float: yes
    number_sections: true
    theme: cerulean
    highlight: haddock
    includes: 
      in_header: '~/github/src/templates/ohara_hdr.html'
  pdf_document:
    toc: true
---

``` {r setup, echo = TRUE, message = FALSE, warning = FALSE}

knitr::opts_chunk$set(fig.width = 6, fig.height = 4, fig.path = 'figs/',
                      echo = TRUE, message = FALSE, warning = FALSE)

source('https://raw.githubusercontent.com/oharac/src/master/R/common.R')
# library(taxize)   ### remotes::install_github("ropensci/taxize")
library(taxizedb) ### remotes::install_github("ropensci/taxizedb")
# taxizedb::db_download_ncbi()
# taxizedb::src_ncbi()
# taxizedb::db_download_gbif()

```

# Summary

From the taxonomic names given by the taxon experts, expand both upward and downward to create an all-inclusive marine species list.

Use the `taxize` package:

* `taxize::classification()` to get the entire taxonomic hierarchy of a given taxon ID.
* `taxize::children()` to get immediate taxonomic children for a given taxon
* `taxize::downstream()` to get names down to a specified rank, e.g., getting all species in a family.

```{r}
### create a function to break up large species lists into chunks,
### saving to tmp, in case of breaks in internet connectivity
classify_chunks <- function(spp_gps, chunk_size = 20, db = 'worms', overwrite = FALSE) {
  ### spp_gps is a character vector
  n_chunks <- ceiling(length(spp_gps) / chunk_size)
  tmpstem <- here('tmp/taxize_classification_all_%s.csv')
  if(overwrite == TRUE) {
    unlink(here('tmp/taxize_classification_all_*.csv'))
  }
  for(i in 1:n_chunks) { ### i <- 1
    message('Processing chunk ', i, ' of ', n_chunks)
    indices <- c(1 + chunk_size * (i - 1), min(length(spp_gps), chunk_size * i))
    chunk_file <- sprintf(tmpstem, paste0(indices, collapse = '_'))
    if(!file.exists(chunk_file)) {
      tmp_gps <- spp_gps[indices[1]:indices[2]]
      
      chunk_results <- taxize::classification(tmp_gps, db = db)
      
      chunk_check <- sapply(chunk_results, is.data.frame)
      chunk_ok <- chunk_results[chunk_check]
      
      chunk_df <- bind_rows(chunk_ok, .id = 'spp_gp') 

      error_results <- chunk_results[!chunk_check]
      if(length(error_results) > 0) {
        message('chunk ', i, ' returned ', length(error_results),
                ' errors out of ', length(tmp_gps))
        chunk_errors <- data.frame(spp_gp = names(error_results),
                                   error = TRUE)
        chunk_df <- chunk_df %>%
          bind_rows(chunk_errors)
      }
    
      write_csv(chunk_df, chunk_file)
    }
  }
  
  tmp_files <- list.files(here('tmp'), pattern = sprintf('taxize_classification_all'),
                          full.names = TRUE)
  
  results_all <- lapply(tmp_files, 
                        FUN = function(f) {
                          read_csv(f, col_types = cols(.default = 'c'))
                        }) %>%
    bind_rows() %>%
    mutate(error = ifelse(is.na(error), FALSE, error),
           error = as.logical(error))
  return(results_all)
}

```

## Match up taxonomic info from experts to names in taxonomic databases.

Using `taxize::classification()`, check each taxonomic name against databases of taxonomic info to get the full upstream classification.  

Order of search:

* NCBI (left 140 still unmatched out of 789 - still need to disaggregate some cephs)
* GBIF (left 12 still unmatched)
* WoRMS (left 14 still unmatched)
* EOL (found the rest - NOTE: this was not a preferred db because some names had extra info, e.g. citation)

```{r, eval = FALSE}
spp_traits <- read_csv('_data/spp_traits_valid.csv') %>%
  filter(!str_detect(spp_gp, 'large eggs|small eggs'))

### This queries for all species
# spp_gps <- spp_traits %>%
#   select(taxon, spp_gp) %>%
#   mutate(name = tolower(spp_gp)) %>%
#   .$spp_gp %>% unique()
# 
# y <- classify_chunks(spp_gps, db = 'ncbi') %>%
#   mutate(db = 'ncbi')
# 
# write_csv(y, here('int/taxize_results_all.csv'))

### this can be iterated to fill gaps.  

y <- read_csv(here('int/taxize_results_all.csv')) %>%
  filter(spp_gp %in% spp_traits$spp_gp) %>%
  left_join(spp_traits %>% select(spp_gp, taxon) %>% distinct())

yy <- spp_traits %>%
  filter(!spp_gp %in% y$spp_gp) %>%
  .$spp_gp %>% unique()
spp_gps_error <- y %>%
  filter(error) %>%
  .$spp_gp %>% unique()

db = 'worms'
z <- classify_chunks(c(yy, spp_gps_error), db = db, overwrite = TRUE) %>%
  mutate(db = db)

z %>% filter(error) %>% .$spp_gp %>% n_distinct()
# z_eol
### 14 still unmatched with WORMS; 6 still unmatched with GBIF; EOL finds the
### rest though still need to break out cephs

zz <- y %>%
  filter(!error) %>%
  bind_rows(z %>% mutate(id = as.numeric(id))) %>%
  select(-taxon)

write_csv(zz, here('int/taxize_results_all.csv'))

```

## Get downstream species based on higher ranks

### Class match

Filter to just the "main" ranks, and then at each of these higher ranks, get downstream species.

```{r}
taxa_raw <- read_csv(here('int/taxize_results_all.csv'))

ranks <- c('kingdom', 'phylum', 'class', 'order', 'family', 'genus', 'species')

taxa_lvls <- taxa_raw %>%
  mutate(name = tolower(name),
         rank = tolower(rank),
         rank = factor(rank, levels = ranks)) %>%
  filter(!is.na(rank))

```

The highest rank at which we were provided information was class (for Demospongiae).  Let's grab all the classes in our dataset and try a massive downstream dump, down to the species level, and see what happens.

Turns out `downstream` even with `intermediate = TRUE` loses connections between levels, e.g. you know which genuses are in an order, but not which family they belong to within that order.  But for those taxa where we have the species level, 

Try instead a sequential `downstream` call but just one level at a time.  Use `downstream` with `intermediate = FALSE` so we can try to skip suborders, subfamilies, etc.

See https://github.com/ropensci/taxize/issues/830#issuecomment-646236702 for notes on taxizedb, downloading NCBI database and working from that locally.


```{r}
### create a function to get and interpret downstream matches for a given taxon,
### saving to tmp, in case of breaks in internet connectivity.  
### taxa is a dataframe containing the id and name for a given rank;
### start_rank is the level of that first dataframe.


get_all_downstream <- function(start_taxa, 
                               start_rank = 'class', 
                               db, 
                               overwrite = FALSE) {
  # start_taxa <- class_db[1, ]
  # start_rank <- 'class'
  
  tmpstem <- here('int/taxize_downstream_%s_%s.csv')
  outfile <- sprintf(tmpstem, start_taxa$name, db)
  if(overwrite == TRUE) {
    unlink(outfile)
  }
  
  if(!file.exists(outfile)) {
    
    ranknums <- 1:length(ranks) %>% setNames(ranks)
    start_num <- ranknums[start_rank]
    
    result_list <- vector('list', length = 6)
    
    i <- start_num
    taxa <- start_taxa
    while(i < 7) {
    
      rankstart  <- ranks[i]
      ranktarget <- ranks[i + 1]
      message('Processing rank ', rankstart)
  
      ds_result <- taxizedb::downstream(x = taxa$id, 
                          db = database, 
                          downto = ranktarget,
                          intermediate = FALSE) 
      
      # if(nrow(ds_result[[1]]) == 0 & i < 6) {
      #   ### this level returned a blank dataframe
      #   i <- i + 1
      #   ranktarget = ranks[i + 1]
      #   ds_result <- taxize::downstream(sci_id = taxa$id, 
      #                       db = database, 
      #                       downto = ranktarget,
      #                       intermediate = FALSE) 
      # }
      # if(nrow(ds_result[[1]]) == 0 & i < 6)
      
      ds_df <- ds_result %>%
        rlang::as_list() %>% ### coerces, rather than converts like as.list()
        setNames(taxa$name) %>%
        bind_rows(.id = rankstart) %>%
        select(childtaxa_id, !!ranktarget := childtaxa_name, !!rankstart)

      result_list[[i]] <- ds_df
      taxa <- ds_df %>%
        select(childtaxa_id, childtaxa_name := !!ranktarget)
      
      i <- i + 1
    }
    
    full_df <- result_list[[start_num]] %>%
      select(-childtaxa_id)
    for(j in (start_num+1) : 6) {
      full_df <- full_df %>%
        left_join(result_list[[j]])
      if(j < 6) full_df <- full_df %>% select(-childtaxa_id)
    }
    full_df <- full_df %>%
      select(class, order, family, genus, species, spp_id = childtaxa_id) %>%
      mutate(db = db)
    
    write_csv(full_df, outfile)
  }
  
  full_df <- read_csv(outfile)

  return(full_df)
}
```

```{r}
### create a function to get and interpret downstream matches for a given taxon,
### saving to intermediate, in case of breaks in internet connectivity.  
### taxa is a dataframe containing the id and name for a given rank;
### start_rank is the level of that first dataframe.


gather_levels <- function(df, start_rank, start_taxa, upstream, db) {
  ranks <- c('kingdom', 'phylum', 'class', 'subclass', 
             'superorder', 'order', 'suborder', 
             'family', 'subfamily', 'genus', 'species')
  if(nrow(df) > 1) stop('gimme just one row to fix, plz')
  df1 <- df %>%
    mutate(rank0 = start_rank,
           id0   = start_taxa$id) %>%
    gather(ranklevel, rank, starts_with('rank')) %>%
    gather(namelevel, name, starts_with('name')) %>%
    gather(idlevel,   id,   starts_with('id')) %>%
    filter(str_extract(namelevel, '[0-9]+') == str_extract(ranklevel, '[0-9]+')) %>%
    filter(str_extract(namelevel, '[0-9]+') == str_extract(idlevel, '[0-9]+')) %>%
    filter(!is.na(name)) %>%
    bind_rows(upstream) %>%
    select(rank, name, id) %>%
    distinct() %>%
    mutate(rank = factor(rank, levels = ranks)) %>%
    arrange(rank) %>%
    mutate(species = last(name),
           db = db)
  
  return(df1)
}

get_all_children <- function(start_taxa, 
                             start_rank = 'class', 
                             db, 
                             overwrite = FALSE) {
  # start_taxa <- class_db[1, ]
  # start_rank <- 'class'
  
  tmpstem <- here('int/taxize_downstream_%s_%s.csv')
  outfile <- sprintf(tmpstem, start_taxa$name, db)
  if(overwrite == TRUE) {
    unlink(outfile)
  }
  
  if(!file.exists(outfile)) {
    
    result_list <- vector('list', length = 20)
    
    i <- 0
    taxa <- start_taxa
    while(nrow(taxa) > 0) {
      i <- i + 1
      message(i)

      ds_result <- taxizedb::children(x = taxa$id, db = database) 
      
      ds_df <- ds_result %>%
        rlang::as_list() %>% ### coerces, rather than converts like as.list()
        setNames(taxa$name) %>%
        bind_rows(.id = 'parent')

      result_list[[i]] <- ds_df
      taxa <- ds_df %>%
        filter(rank != 'species') %>%
        select(-parent)
      
    }
    result_list <- result_list[1:i]
    
    
    full_df <- bind_rows(result_list) %>%
      mutate(name = tolower(name), parent = tolower(parent)) %>%
      rename(name1 = name, rank1 = rank, id1 = id, name0 = parent)

    tmp_df <- full_df
    
    for(j in 2:i) {
      ### j <-2
      oldname <- paste0('name', j-1)
      newname <- paste0('name', j)
      newrank <- paste0('rank', j)
      newid   <- paste0('id', j)
      ### fix names without variables; rename after
      join_df <- full_df %>%
        rename(newname = name1,
               newid   = id1,
               newrank = rank1,
               parent = name0)
               
      tmp_df <- tmp_df %>%
        rename(parent := oldname) %>%
        left_join(join_df, tmp_df, by = c('parent')) %>%
        rename(!!oldname := parent,
               !!newname := newname,
               !!newid   := newid,
               !!newrank := newrank)
    }
    
    upstream <- classification(start_taxa$id, db = db)[[1]] %>%
      filter(rank %in% ranks) %>%
      mutate(name = tolower(name))
      
    clean_df <- parallel::mclapply(1:nrow(tmp_df), FUN = function(i) {
          df <- tmp_df[i, ]
          gather_levels(df, start_rank, start_taxa, upstream, db)
        }) %>%
      bind_rows()
    
    write_csv(clean_df, outfile)
  }
  
  clean_df <- read_csv(outfile)

  return(clean_df)
}
```

```{r}

database <- 'ncbi'
class_db <- taxa_lvls %>%
  filter(db == database & !error) %>%
  group_by(name) %>%
  mutate(n = n_distinct(spp_gp)) %>%
  ungroup() %>%
  filter(rank == 'class') %>%
  arrange(desc(n)) %>%
  select(id, name) %>%
  distinct()


for(i in 1:nrow(class_db)) {
  ### i <- 1
  taxa <- class_db[i, ]
  cat('Processing ', taxa$name, '...\n')
  x <- get_all_children(start_taxa = taxa,
                        start_rank = 'class', 
                        db = database, overwrite = FALSE)

}  

```
